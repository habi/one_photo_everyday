{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 7777 video - 'everyday' alignment 2nd attempt\n",
    "\n",
    "This notebook shows the full code base needed to align all of Noah's images from the 'everyday' project and create the video [7777](https://www.youtube.com/watch?v=DC1KHAxE7mo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('Tc2WPoR-zlw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, we use [dlib](http://dlib.net/) toolbox to detect, extract and align faces from all the images. The process to do so is a 2-step process:\n",
    "\n",
    "1. We use `hog_detector` detector to find the faces in all images. This detector is 'ok-ish' but runs very quickly.\n",
    "2. For all images where it wasn't possible to detect a face, we use the `cnn_face_detection_model_v1` routine. This routine is slower but more accurate.\n",
    "\n",
    "Dlib's face detection is usually used to extract small 'chips'/patches of pixels that only contain the face. In this case however we decided to keep the full image, but just profit from dlib's routine of aligning the faces according to the 5 landmarks (two eyes, nose and two corners of the mouth). During this procedure, images are also upscaled to 4k (3840, 2160) resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Acquisition\n",
    "\n",
    "First things first, let's collect all photos from the video with `pytube`. If the package is not yet installed on your machine you can do so with `pip install pytube`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's install pytube and a few other python packages\n",
    "!pip install -qU pytube opencv-python tqdm ipywidgets scikit-learn scikit-image tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Download the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download video\n",
    "video_url = 'https://www.youtube.com/watch?v=Tc2WPoR-zlw'\n",
    "out_folder = 'video'\n",
    "filename = 'boy'\n",
    "yt_streams = YouTube(video_url).streams.filter(progressive=True, type='video', res='720p')\n",
    "yt_streams.first().download(out_folder, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Extract all individual images\n",
    "\n",
    "*First*, we will use the package OpenCV to load all images from the video. *Second*, we will go through all the images and only keep unique images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from glob import glob\n",
    "from matplotlib import patches\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video with OpenCV and extract relevant parameters\n",
    "video = cv2.VideoCapture(os.path.join(out_folder, filename+'.mp4'))\n",
    "video_frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print('Video has %d number of frames.' % video_frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack to keep unique images\n",
    "imgs = []\n",
    "\n",
    "# Looping through all images, and only adding them to the stack if they are new\n",
    "for idx in tqdm(np.arange(video_frame_count)):\n",
    "\n",
    "    # Read frame\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "    frame_retrieved, frame = video.read()\n",
    "    \n",
    "    # Check if image is new by correlating it to previous frame\n",
    "    if frame_retrieved:\n",
    "        if len(imgs)>0 and np.corrcoef(frame.ravel(), imgs[-1].ravel())[0, 1]>0.99:\n",
    "            continue\n",
    "        imgs.append(frame)\n",
    "\n",
    "# Transform stack into numpy array and switch colorcode from BGR to RGB\n",
    "imgs = np.array(imgs)[..., ::-1]\n",
    "\n",
    "print('Dataset has shape of', imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all images on disk\n",
    "for idx in tqdm(range(len(imgs))):\n",
    "    plt.imsave(f'img_orig/plot_{idx:03d}.png', imgs[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all file names\n",
    "filenames = sorted(glob('img_orig/*'))\n",
    "filenames[:5] + filenames[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct and align images with `skimage` and `dlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show last image in the dataset\n",
    "last_img = io.imread(filenames[-1])\n",
    "plt.title(last_img.shape)\n",
    "plt.imshow(last_img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder for aligned images\n",
    "out_dir = 'img_aligned'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "# Additional dlib models for face recognition\n",
    "shape_predictor = dlib.shape_predictor('dlib/shape_predictor_5_face_landmarks.dat') # Faces landmarks (points)\n",
    "\n",
    "# Which face detector to use\n",
    "hog_detector = dlib.get_frontal_face_detector()\n",
    "cnn_detector = dlib.cnn_face_detection_model_v1('dlib/mmod_human_face_detector.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_chip_size = (1920, 1080) # full hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img, dim=(1920, 1080), ratio=7.):\n",
    "    offset = int(dim[0]/ratio)\n",
    "    return img[offset:offset+dim[1], ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go through with hog_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN is more advanced but takes longer; hog misses ~100 faces in total\n",
    "face_detector = hog_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_files = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "padding = np.divide(*face_chip_size)\n",
    "\n",
    "issues = []\n",
    "\n",
    "if align_files:\n",
    "\n",
    "    for f in tqdm(filenames):\n",
    "\n",
    "        # Specify new filename\n",
    "        new_filename = os.path.join('img_aligned', os.path.basename(f))\n",
    "        if os.path.exists(new_filename):\n",
    "            continue\n",
    "\n",
    "        # Load image\n",
    "        im = io.imread(f)[..., :3]\n",
    "\n",
    "        # Get information about image size\n",
    "        w, h = im.shape[:2]\n",
    "        offset = (h - w)//2\n",
    "\n",
    "        \"\"\"\n",
    "        # Correct image intensity\n",
    "        plow, phigh = np.percentile(im, (0, 99))\n",
    "        im_corrected = rescale_intensity(im, in_range=(plow, phigh))\n",
    "        \"\"\"\n",
    "\n",
    "        # Center image in a canvas\n",
    "        canvas = np.zeros((h, h, 3)).astype('uint8')\n",
    "        canvas[...] = im\n",
    "\n",
    "        # Detect faces and align image\n",
    "        rectangles = [x if isinstance(x, dlib.rectangle) else x.rect for x in face_detector(canvas, 1)]\n",
    "        if len(rectangles):\n",
    "            landmarks = [shape_predictor(canvas, r) for r in rectangles]\n",
    "            face_chips = [dlib.get_face_chip(canvas, l, size=face_chip_size[0],\n",
    "                                             padding=padding) for l in landmarks]\n",
    "\n",
    "            # Crop image to write ratio\n",
    "            img_final = crop_img(face_chips[0], dim=face_chip_size, ratio=7)\n",
    "            img_final = img_final[80:-80, 500:-500]\n",
    "\n",
    "            # Save aligned image\n",
    "            io.imsave(new_filename, img_final)\n",
    "\n",
    "        else:\n",
    "            print('new issue found:', f)\n",
    "            issues.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(issues))\n",
    "issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go through issue images with cnn_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN is more advanced but takes longer; hog misses ~100 faces in total\n",
    "face_detector = cnn_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "padding = np.divide(*face_chip_size)\n",
    "\n",
    "issues_still = []\n",
    "\n",
    "for f in tqdm(issues):\n",
    "    \n",
    "    # Load image\n",
    "    im = io.imread(f)[..., :3]\n",
    "    \n",
    "    # Get information about image size\n",
    "    w, h = im.shape[:2]\n",
    "    offset = (h - w)//2\n",
    "    \n",
    "    \"\"\"\n",
    "    # Correct image intensity\n",
    "    plow, phigh = np.percentile(im, (0, 99))\n",
    "    im_corrected = rescale_intensity(im, in_range=(plow, phigh))\n",
    "    \"\"\"\n",
    "\n",
    "    # Center image in a canvas\n",
    "    canvas = np.zeros((h, h, 3)).astype('uint8')\n",
    "    canvas[...] = im\n",
    "\n",
    "    # Detect faces and align image\n",
    "    rectangles = [x if isinstance(x, dlib.rectangle) else x.rect for x in face_detector(canvas, 1)]\n",
    "    if len(rectangles):\n",
    "        landmarks = [shape_predictor(canvas, r) for r in rectangles]\n",
    "        face_chips = [dlib.get_face_chip(canvas, l, size=face_chip_size[0],\n",
    "                                         padding=padding) for l in landmarks]\n",
    "        \n",
    "        # Crop image to write ratio\n",
    "        img_final = crop_img(face_chips[0], dim=face_chip_size, ratio=7)\n",
    "        img_final = img_final[80:-80, 500:-500]\n",
    "\n",
    "        # Save aligned image\n",
    "        io.imsave(os.path.join('img_aligned', os.path.basename(f)), img_final)\n",
    "        \n",
    "    else:\n",
    "        print('new issue found:', f)\n",
    "        issues_still.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(issues_still))\n",
    "issues_still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images\n",
    "print(len(filenames), len(glob('img_aligned/plot*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup video parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all filenames\n",
    "imgs = sorted(glob('img_aligned/plot*'))\n",
    "\n",
    "# Extract number of images\n",
    "N_total = len(imgs)\n",
    "N_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify frames per second\n",
    "fps = 24\n",
    "\n",
    "print('Video length: %.2f seconds.' % (N_total/fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create aligned video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images to disk\n",
    "out_dir = 'img_video_aligned'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# To keep track what was already loaded\n",
    "already_loaded = []\n",
    "\n",
    "for i in tqdm(np.arange(len(imgs))):\n",
    "    \n",
    "    im = io.imread(imgs[i])\n",
    "    \n",
    "    # Create out_filename\n",
    "    out_filename = os.path.join(out_dir, '%04d.jpg' % (i + 1))\n",
    "    \n",
    "    # Save composition image\n",
    "    io.imsave(out_filename, im.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use either code (the one that works) to create the video\n",
    "!cat img_video_aligned/*jpg | ffmpeg -f image2pipe -r $fps -vcodec mjpeg -i - -vcodec libx264 video_aligned.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create averaged images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images to smooth at once\n",
    "smooth = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many days to jump at every image\n",
    "step_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get start indeces for images\n",
    "ids = [i*step_size for i in range((N_total+smooth)//step_size+1)]\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images to disk\n",
    "out_dir = 'img_video_%ddays_mean' % (smooth)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# To keep track what was already loaded\n",
    "already_loaded = []\n",
    "\n",
    "for i in tqdm(ids):\n",
    "    \n",
    "    # Collect indeces of images\n",
    "    imgs_idx = np.arange(np.clip(i-smooth, 0, N_total-1), np.clip(i, 0, N_total-1)+1)\n",
    "\n",
    "    # Collect images relevant for the group\n",
    "    group_names = np.array(imgs)[imgs_idx]\n",
    "    \n",
    "    # Detect which one is new to load\n",
    "    new_to_load = np.setdiff1d(group_names, already_loaded)\n",
    "    \n",
    "    if len(new_to_load)==0:\n",
    "        pass\n",
    "    elif i==0:\n",
    "        imgs_group = np.array([io.imread(f) for f in new_to_load])\n",
    "    else:\n",
    "        img_new = np.array([io.imread(f) for f in new_to_load])\n",
    "        imgs_group = np.vstack((imgs_group, img_new))\n",
    "        \n",
    "    # Cut imgs_group to write size\n",
    "    n_offset = (i - N_total)\n",
    "    if n_offset <= 0:\n",
    "        n_offset = 0\n",
    "    elif n_offset%2==0:\n",
    "        n_offset -= 1\n",
    "    imgs_group = imgs_group[-smooth+n_offset:]\n",
    "    \n",
    "    # Create composition image\n",
    "    img_comp = np.mean(imgs_group, axis=0).astype('int')\n",
    "    \n",
    "    # Create out_filename\n",
    "    out_filename = os.path.join(out_dir, '%04d.jpg' % (i + 1))\n",
    "    \n",
    "    # Save composition image\n",
    "    io.imsave(out_filename, img_comp.astype('uint8'))\n",
    "\n",
    "    # Keep track of what has already been loaded\n",
    "    already_loaded = group_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use either code (the one that works) to create the video\n",
    "!cat img_video_30days_mean/*jpg | ffmpeg -f image2pipe -r $fps -vcodec mjpeg -i - -vcodec libx264 video_30days_mean.mp4\n",
    "#!ffmpeg -r 30 -f image2 -pattern_type glob -i 'img_video_30days_mean/*.jpg' -c:v libx264 -profile:v high video_30days_mean.mp4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
